---
output: 
    html_document:
      css: solarized-light.css
---
[Home](https://peterwsetter.github.io)

```{r setup, include=FALSE}
knitr::opts_chunk$set(message = FALSE, warning = FALSE)
```

## A purrr Resource

#### Motivation

I was very interested in purrr when it was [first released](https://blog.rstudio.org/2015/09/29/purrr-0-1-0/), but I quickly ran into a wall when I tried using it in my own analysis. This post will be periodically updated with tips and tricks that I found helpful when learning to use it.

Before getting started, view this [talk from Hadley](https://t.co/PQjHCf4eO2) where he explains -- by cupcake-baking analogy -- the usefulness of functional programming. Hadley is designing purrr as a successor to the `.*apply` family (and his own plyr package), but this [Stack Overflow thread](http://stackoverflow.com/questions/3505701/r-grouping-functions-sapply-vs-lapply-vs-apply-vs-tapply-vs-by-vs-aggrega) is a great resource for using the base-R functions.

#### Applying Functions by Group

A common task in my workflow is applying a function on two or more variables over a grouping variable. For example, using the [College Scorecard](https://catalog.data.gov/dataset/college-scorecard) dataset, what is the correlation between admission rate and middle ACT composite depending on school control (Public, Private Non-Profit, Private For-Profit)?

```{r}
library(dplyr)
library(purrr)
library(data.table)
library(ggplot2)
library(gridExtra)

# Download the data and read in 
url <- 'https://s3.amazonaws.com/ed-college-choice-public/Most+Recent+Cohorts+(All+Data+Elements).csv'
destfile <- 'college-scorecard.csv'

if(!file.exists(destfile)) {
    download.file(url, destfile)
}

college.scorecard <- fread(destfile, na.strings = 'NULL')

# First, determine if the data is normally distributed

plot.adm <- ggplot(data = college.scorecard) +
    geom_density(aes(ADM_RATE))

plot.act <- ggplot(data = college.scorecard) +
    geom_density(aes(ACTCMMID))

grid.arrange(plot.adm, plot.act, nrow = 1)

college.scorecard %>%
    aov(ADM_RATE ~ ACTCMMID, data = .) %>%
    residuals() %>%
    shapiro.test

# p << 0.05, indicating non-normality, therefore, we'll use Spearman correlation
# `1` = Public, `2` = Private Non-Profit, `3` = Private For-Profit
college.scorecard %>%
    split(.$CONTROL) %>%
    map(function(df) with(df, cor(ADM_RATE, ACTCMMID, 
                                  use = 'complete.obs',
                                  method = 'spearman')))
```

The first step is to create groups using `split`, then apply the function using the `map(function(df) with(df, ...))` syntax.

This worth noting that this can also be accomplished using `dplyr::summarize`.

```{r}
college.scorecard %>%
    group_by(CONTROL) %>%
    summarize(spearman = cor(ADM_RATE, ACTCMMID, 
                             use = 'complete.obs', 
                             method = 'spearman'))
```

This raises the question: 

#### When is it best to use `summarize` and when is it best to use `map`? 

Let's compare how these functions handle a linear model.

```{r}
college.scorecard %>%
    split(.$CONTROL) %>%
    map(function(df) lm(ADM_RATE ~ ACTCMMID, data = df)) 

college.scorecard %>%
    group_by(CONTROL) %>%
    summarize(model = lm(ADM_RATE ~ ACTCMMID, data = .)) 
```

Using `map` produces the output we expect -- and presumably want -- a list with the three models. Using `summarize`, we have a data frame with 13 columns per CONTROL value. What's going on?

```{r}
summarize.lm <- college.scorecard %>%
    group_by(CONTROL) %>%
    summarize(model = lm(ADM_RATE ~ ACTCMMID, data = .)) 

summarize.lm$model[c(1, 11)]
```

For `summarize` every row in the output is a separate part of the `lm` object. There may be a use-case when this is helpful, but, in general, `map` is more appropriate.

In general, if you want a *summary* statistic, `summarize` is more appropriate. If you have a complex output type, it's better to use `map`.